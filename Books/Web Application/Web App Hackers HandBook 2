Chapter 1: Web Application (In)security
    1:  Evolution Of Web Applications:
        -> In early days www for repo of sites with static documents and web browsers were made to display them it had one way flow server to browser. No Authentication, Everyone was treated equally, Most of the vulnerabilities were in hosting servers and bugs in hosting softwares, if attackers gains access he will not get anything confidential because everything is open but he can modify.
        -> Today www is now all new, most of the websites are now web applications an rely on 2 way flow, now supports registrations, logins, transactions, search, authoring of the content, content is now presented dynamically and tailored to specific users, most of the info is private and sensitive, security is a big concern, most of the web apps made in home by developers who have partial knowledge about security, web apps normally require connectivity to internal networks or nodes which have all the sensitive data in them.
    
    2:  Common Web Application Functions:
        -> Web Applications can be made for any thing like shopping, social networking, banking, search, interactive information etc.
        -> Web applications are widely used organizations to support key business functions.
        -> HR applications allowing users to access payroll information, give and receive performance feedback, and manage recruitment and disciplinary procedures.
        -> Administrative interfaces to key infrastructure such as web and mail servers, user workstations, and virtual machine administration.
        -> Business applications such as enterprise resource planning (ERP) software, which previously were accessed using a proprietary thick-client application, can now be accessed using a web browser.
        -> Software services such as e-mail, which originally required a separate e-mail client, can now be accessed via web interfaces such as Outlook Web Access.
        -> Traditional desktop office applications such as word processors and spreadsheets have been migrated to web applications through services such as Google Apps and Microsoft Office Live.
        -> organizations move to outside service providers to cut costs
    
    3:  Benefits Of Web applications
        -> www is accessed through http, http is lightweight and connectionless. no need to hold open connection for each user,http can be proxied and tunneled to other protocols allowing secure communication in any network.
        -> Web applications deploy their user interface dynamically to the browser, avoiding the need to distribute and manage separate client software
        -> Client-side scripting enables applications to push part of their processing to the client side, and browsers’ capabilities can be extended in arbitrary ways using browser extension technologies where necessary.

    4: Web Application Security
        -> The most serious attacks against web applications are those that expose sensitive data or gain unrestricted access to the back-end systems on which the application is running.
        -> system downtime is a loss for companies and organizations.
        -> majority of web applications are insecure, despite the widespread usage of SSL technology and the adoption of regular PCI scanning.
        -> Broken Authentication: This category of vulnerability encompasses various defects within the application’s login mechanism, which may enable an attacker to guess weak passwords, launch a brute-force attack, or bypass the login.
        -> Broken Access Control: This involves cases where the application fails to properly protect access to its data and functionality, potentially enabling an attacker to view other users’ sensitive data held on the server or carry out privileged actions.
        -> Sql Injection: This vulnerability enables an attacker to submit crafted input to interfere with the application’s interaction with back-end databases. An attacker may be able to retrieve arbitrary data from the application, interfere with its logic, or execute commands on the database server itself.
        -> Cross-site Scripting: This vulnerability enables an attacker to target other users of the application, potentially gaining access to their data, performing unauthorized actions on their behalf, or carrying out other attacks against them.
        -> Information Leakage: This involves cases where an application divulges sensitive information that is of use to an attacker in developing an assault against the application, through defective error handling or other behavior.
        -> Cross-site Request Forgery: This fl aw means that application users can be induced to perform unintended actions on the application within their user context and privilege level. The vulnerability allows a malicious web site visited by the victim user to interact with the application to perform actions that the user did not intend.
        -> ssl will save your data from eavesdroppers while transmitting it between web browser and server.
        -> ssl will not prevent direct attacks on server and client component.
    
    5: Core Security Problems:
        -> Users Can Submit Arbitrary Input:
            --> The application must assume that all input is potentially malicious.
            --> Users can interfere with any piece of data transmitted between the client and the server, including request parameters, cookies, and HTTP headers. Any security controls implemented on the client side, such as input validation checks, can be easily circumvented.
            --> Users can send requests in any sequence and can submit parameters at a different stage than the application expects, more than once, or not at all.
            --> Majority of attacks against web applications involve sending input to the server that is crafted to cause some event that was not expected or desired by the application’s designer.
            --> SSL does not stop an attacker from submitting crafted input to the server.

Chapter 2: Core Defense Mechanisms
    1: Handling User Access
        -> Authentication: process of validating that the user is in fact who he claims to be. Without this facility, the application would need to treat all users as anonymous, the lowest level of trust.
        -> Session Management: all web applications meet this requirement by creating a session for each user and issuing the user a token that identifies the session. The session itself is a set of data structures held on the server that track the state of the user’s interaction with the application. The token is a unique string that the application maps to the session. When a user receives a token, the browser automatically submits it back to the server in each subsequent HTTP request, enabling the application to associate the request with that user. majority of attacks it seeks is to compromise the session token issued to other user, if its possible then it will result in complete account takeover. vulnerability can be found in how tokens are generated, enabling an attacker to guess the tokens issued to other users, and defects in how tokens are subsequently handled, enabling an attacker to capture other users’ tokens.
        -> Access Control: If the mechanisms just described are functioning correctly, the application knows the identity of the user from whom each request is received. On this basis, it needs to decide whether that user is authorized to perform the action, or access the data, that he is requesting. The access control mechanism usually needs to implement some fi  ne-grained  logic, with different considerations being relevant to different areas of the application and different types of functionality. Because of the complex nature of typical access control requirements, this mechanism is a frequent source of security vulnerabilities that enable an attacker to gain unauthorized access to data and functionality.
    
    2: Handling User Input:
        -> Approaches To Input Handling:
            --> Reject Known Bad: This approach typically employs a blacklist containing a set of literal strings or patterns that are known to be used in attacks. The validation mechanism blocks any data that matches the blacklist and allows everything else.
                
                Many blacklist-based filters can be bypassed with almost embarrassing ease by making trivial adjustments to the input that is being blocked. For example: 
                    -> If SELECT is blocked, try SeLeCt
                    -> If or 1=1-- is blocked, try or 2=2--n
                    -> If alert(‘xss’) is blocked, try prompt(‘xss’)
            
                In other cases, filters designed to block specific keywords can be bypassed by using nonstandard characters between expressions to disrupt the tokenizing performed by the application. For example:
                
                    -> SELECT/*foo*/username,password/*foo*/FROM/*foo*/users
                    -> <img%09onerror=alert(1) src=a>

            --> Accept Known Goods: This approach employs a whitelist containing a set of literal strings or patterns, or a set of criteria, that is known to match only benign input. The validation mechanism allows data that matches the whitelist and blocks everything else. 

            --> Sanitization: This approach sanitizes the input i different ways like s. Potentially mali-cious characters may be removed from the data, leaving only what is known to be safe, or they may be suitably encoded or “escaped” before further processing is performed. 

            --> Safe Data Handling: Many web application vulnerabilities arise because user-supplied data is pro-cessed in unsafe ways. Vulnerabilities often can be avoided not by validating the input itself but by ensuring that the processing that is performed on it is inherently safe. In some situations, safe programming methods are available that avoid common problems.

            --> Semantic Checks: Check for malformed crafted data.

        -> Boundary Validation:  
            --> Input validation checks implemented on the client side may improve performance and the user’s experience, they do not provide any assurance about the data that actually reaches the server.
            
            --> The role of input validation is to clean potentially malicious data on arrival and then pass the clean data to the trusted application. From this point onward, the data may be trusted and processed without any further checks or concern about possible attacks.
            
            --> Many application functions involve chaining together a series of different types of processing. A single piece of user-supplied input might result in a number of operations in different components, with the output of each being used as the input for the next. As the data is transformed, it might come to bear no resemblance to the original input.

            --> Preventing cross-site scripting attacks may require the application to HTML-encode the > character as &gt;, and preventing command injection attacks may require the application to block input containing the & and ; characters. Attempting to prevent all categories of attack simultaneously at the application’s external boundary may sometimes be impossible.

            -->  This model provides a solution to the problems just described. Each component can defend itself against the specifi c types of crafted input to which it may be vulnerable. As data passes through different components, validation checks can be performed against whatever value the data has as a result of previous transformations. And because the various validation checks are implemented at different stages of processing, they are unlikely to come into conflict with one another.

            --> User Login suitable validation at each step
                
                - application receives login info, form handler checks for length and known attack signatures.

                - Sql query is performed for user validation and all the characters which can construct a sql injection has ben removed before making the query.

                - if login succeeds, applications will pass specific information to SOAP service to retrieve future information, to prevent SOAP injection attacks, any XML meta characters within the user's profile data are suitably encoded.

                - The application displays the user’s account information back to the user’s browser. To prevent cross-site scripting attacks, the application HTML-encodes any user-supplied data that is embedded into the returned page.

        -> Multi-step Validation and Canonicalization

            --> if <script> tag is being sanitized an attacker can use something like this <scr<script>ipt> when the <script> tag is removed the surrounding data will contract and will become that tag again. because the filter is not applied recursively.
            --> if application removes ../ recursively and then remove ..\ then it can be defeated by ....\/
            --> if application blocks the apostrophe character then you can use %2527, when normal url decode happens it will become %27 and when application perform further url decode it will become '

    3: Handling Attackers
        -> Handling Errors:
            --> A key defense mechanism is for the application to handle unexpected errors gracefully, and either recover from them or present a suitable error message to the user.

            -->  most application servers can be confi gured to deal with unhandled application errors in customized ways, such as by presenting an uninformative error message.

            -->  Unexpected errors often point to defects within the application’s defenses that can be addressed at the source if the application’s owner has the required information.

        -> Maintaining Audit Logs:
            --> Audit logs are valuable primarily when investigating intrusion attempts against an application.

            --> key events should be logged like:
                - All events relating to the authentication functionality, such as successful and failed login, and change of password.
                - Key transactions, such as credit card payments and funds transfers.
                - Access attempts that are blocked by the access control mechanisms.
                - Any requests containing known attack strings that indicate overtly malicious intentions.

            --> Effective audit logs typically record the time of each event, the IP address from which the request was received, and the user’s account (if authenticated). Such logs need to be strongly protected against unauthorized read or write access.

            --> Poorly protected audit logs can provide a gold mine of information to an attacker, disclosing a host of sensitive information such as session tokens and request parameters. This information may enable the attacker to immediately compromise the entire application.

        -> Alerting Administrators:
            --> Audit logs enable an application’s owners to retrospectively investigate intrusion attempts and, if possible, take legal action against the perpetrator.

            --> it's more reliable to do a realtime action like blocking the ip address from which attack payloads are coming.

            --> Alerting mechanisms often include the following factors to report:

                - Usage anomalies, such as large numbers of requests being received from a single IP address or user, indicating a scripted attack.
                - Business anomalies, such as an unusual number of funds transfers being made to or from a single bank account.
                - Requests containing known attack strings.
                - Requests where data that is hidden from ordinary users has been modified.

        -> Reacting To Attacks
        
    4: Managing The Application:
        -> Administrative functions are implemented within the application itself, accessible through the same web interface as its core non security functionality.

        -> The administrative mechanism represents a critical part of the application’s attack surface. Its primary attraction for an attacker is as a vehicle for privilege escalation.
            --> Weaknesses in the authentication mechanism may enable an attacker to gain administrative access, effectively compromising the entire application.

            --> Many applications do not implement effective access control of some of their administrative functions. An attacker may fi nd a means of creating a new user account with powerful privileges.

            --> Administrative functionality often involves displaying data that originated from ordinary users. Any cross-site scripting fl aws within the administrative interface can lead to compromise of a user session that is guaranteed to have powerful privileges.

            --> Administrative functionality is often subjected to less rigorous security testing, because its users are deemed to be trusted, or because penetration testers are given access to only low-privileged accounts. 

Chapter 3: Web Application Technologies
    1: The HTTP Protocols
        -> Hypertext Transfer Protocol
            --> originally made to fetch static web pages

            --> HTTP uses a message-based model in which a client sends a request mes-sage and the server returns a response message. 

            --> protocol is essentially connection-less: although HTTP uses the stateful TCP protocol as its transport mechanism.

        -> HTTP Request
            --> GET Method is used to retrieve resources from the web server.

            --> GET Method does not have body message.

            --> The query string is indicated by the ? character in the URL.

            --> Most Browsers use HTTP 1.1 as default.

            --> Host Request Header is mandatory.

            --> The Referer header is used to indicate the URL from which the request originated.

            --> The User-Agent header is used to provide information about the browser or other client software that generated the request.

            --> The Host header specifies the hostname that appeared in the full URL being accessed. This is necessary when multiple websites are hosted on the same server, because the URL sent in the fi  rst line of the request usu-ally does not contain a hostname.
            
            --> The Cookie header is used to submit additional parameters that the server has issued to the client
        
        -> HTTP Response
            --> First line of every HTTP response consists of three item.
                    - HTTP Version being used.
                    - A numeric status code indicating the result of the request.
            --> Some Other points
                    - Information contained in server header may or may not be accurate.
                    - Pragama header instructs browser to not store any response in server.
                    - Expirer header indicates that response content has expired. In Case of dynamic content

        -> HTTP Methods 
            --> Get Method:
                    - It is used to retrieve resources from the URL(Uniform Resource Locator).
                    - URL's are also transmitted in Referer header when external links are followed.
                    - That's why query strings should not transmit any sensitive information.

            --> Post Method:
                    - It is designed to perform actions.
                    - With this method, request parameter can be sent in both url string and in the body of the message.
                    - If you try to visit the previous page(using the back button) which was generated using this method, browser will generate a warning and by confirming it browser will generate that request again.
            
            --> Some Other Points
                    - Head method is used to check if resource is available before generating a Get Request.
                    - Trace Method is used to detect if proxy server is manipulating the request or not because it will send strings in body tab and server will respond with same strings in body tab.
                    - Options Method will ask the server about the http method for a particular resource and server will return a response containing an allow header that lists the available method.
                    - Put method tries to upload a file on server using the content contained in the body. If this method is enabled attacker may be able to perform an attack like uploading an arbitrary script and executing it on server.

        -> URLs
            --> An Uniform Resource Locator(URL) is a unique identifier for a specific web resource.
            --> Format
                    - protocol://hostname[:port]/[path/]file[?param=value]
                    - Serveral components are optional, like port if the server is not using the defaults.
            
            -->  URI
                    - Uniform Resource Identifier
                    - Url And Uri Are Same.
                    - It is really used in formal specifications and by those who want t exhibit their pedantry.

        -> REST
            --> Representational State Transfer
            --> 